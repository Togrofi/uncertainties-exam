{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Togrofi/uncertainties-exam/blob/main/UncertaintiesExam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oM3NP03lt0h"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn import Parameter\n",
        "from torch.utils.data import Subset, DataLoader, RandomSampler, SubsetRandomSampler\n",
        "from torch.optim import Adam, SGD\n",
        "from tqdm import tqdm\n",
        "from hyperopt import hp, tpe, fmin\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "params = {\n",
        "    'beta': 1,\n",
        "    'proportion_of_dataset': 1,\n",
        "    'threshold': 0.1,\n",
        "    'experiment_name': 'split', # 'split', 'permuted', 'random'\n",
        "    'perform_vcl': True,\n",
        "    'perform_auto_vcl': True,\n",
        "    'batch_size': 16384*2,\n",
        "}\n",
        "\n",
        "\n",
        "permuted_params = {\n",
        "    'epochs': 10,\n",
        "    'coreset_size': 200,\n",
        "    'num_tasks': 10,\n",
        "    'hidden_dim': 256\n",
        "}\n",
        "\n",
        "split_params = {\n",
        "    'epochs': 10,\n",
        "    'coreset_size': 40,\n",
        "    'hidden_dim': 256\n",
        "}\n",
        "\n",
        "random_split_params = {\n",
        "    'epochs': 10,\n",
        "    'coreset_size': 40,\n",
        "    'num_clients': 10,\n",
        "    'hidden_dim': 256\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6T3YPtufAir"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynx9u5CqNRGA"
      },
      "outputs": [],
      "source": [
        "#@title Create Permuted Data\n",
        "def get_permuted_dataloaders(num_tasks):\n",
        "    batch_size = params['batch_size']\n",
        "    dataset = datasets.MNIST\n",
        "    dataloaders = []\n",
        "\n",
        "    for task in range(num_tasks):\n",
        "        if task == 0:\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((28, 28)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ])\n",
        "        else:\n",
        "            rng_permute = np.random.RandomState(task)\n",
        "            idx_permute = torch.from_numpy(rng_permute.permutation(28*28))\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((28, 28)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                transforms.Lambda(lambda x, idx=idx_permute: x.view(-1)[idx].view(1, 28, 28))\n",
        "            ])\n",
        "\n",
        "        full_task_trainset = dataset(root=\"./data\", train=True, download=True, transform=transform)\n",
        "        jump_size = int(1 / params['proportion_of_dataset'])\n",
        "        task_trainset = Subset(full_task_trainset, range(0, len(full_task_trainset), jump_size))\n",
        "        task_train_sampler = RandomSampler(task_trainset)\n",
        "        task_train_loader = DataLoader(task_trainset, batch_size=batch_size, sampler=task_train_sampler)\n",
        "\n",
        "        full_task_testset = dataset(root=\"./data\", train=False, download=True, transform=transform)\n",
        "        jump_size = int(1 / params['proportion_of_dataset'])\n",
        "        task_testset = Subset(full_task_testset, range(0, len(full_task_testset), jump_size))\n",
        "        task_test_sampler = RandomSampler(task_testset)\n",
        "        task_test_loader = DataLoader(task_testset, batch_size=batch_size, sampler=task_test_sampler)\n",
        "\n",
        "        dataloaders.append((task_train_loader, task_test_loader))\n",
        "\n",
        "    return dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHkWKwgMJyzl"
      },
      "outputs": [],
      "source": [
        "#@title Create Split Data\n",
        "def _extract_class_specific_idx(dataset, target_classes):\n",
        "    idx = torch.zeros_like(dataset.targets, dtype=torch.bool)\n",
        "    for target in target_classes:\n",
        "        idx = idx | (dataset.targets==target)\n",
        "\n",
        "    return idx\n",
        "\n",
        "def get_split_dataloaders(class_distribution):\n",
        "    batch_size = params['batch_size']\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.MNIST\n",
        "    trainset = dataset(root=\"./data\", train=True, download=True, transform=transform)\n",
        "    testset = dataset(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "    dataloaders = []\n",
        "\n",
        "    for i, classes in enumerate(class_distribution):\n",
        "        offset = 2 * i\n",
        "        train_idx = _extract_class_specific_idx(trainset, classes)\n",
        "        train_idx = torch.where(train_idx)[0]\n",
        "        sub_train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "        sub_train_loader = torch.utils.data.DataLoader(\n",
        "            trainset, batch_size=batch_size, sampler=sub_train_sampler)\n",
        "        trainset.targets[sub_train_sampler.indices] -= offset\n",
        "\n",
        "        test_idx = _extract_class_specific_idx(testset, classes)\n",
        "        test_idx = torch.where(test_idx)[0]\n",
        "        sub_test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
        "        sub_test_loader = torch.utils.data.DataLoader(\n",
        "            testset, batch_size=batch_size, sampler=sub_test_sampler)\n",
        "        testset.targets[sub_test_sampler.indices] -= offset\n",
        "\n",
        "        dataloaders.append((sub_train_loader, sub_test_loader))\n",
        "\n",
        "    random.shuffle(dataloaders)\n",
        "    return dataloaders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvLvzdhf1aiM"
      },
      "outputs": [],
      "source": [
        "#@title Create Random Split Data\n",
        "def get_random_split_dataloaders(class_distribution, num_clients):\n",
        "    batch_size = params['batch_size']\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.MNIST\n",
        "    trainset = dataset(root=\"./data\", train=True, download=True, transform=transform)\n",
        "    testset = dataset(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "    all_tasks = []\n",
        "\n",
        "    for i, classes in enumerate(class_distribution):\n",
        "        offset = 2 * i\n",
        "        train_idx = _extract_class_specific_idx(trainset, classes)\n",
        "        train_idx = torch.where(train_idx)[0]\n",
        "        sub_train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "        sub_train_loader = torch.utils.data.DataLoader(\n",
        "            trainset, batch_size=batch_size, sampler=sub_train_sampler)\n",
        "        trainset.targets[sub_train_sampler.indices] -= offset\n",
        "\n",
        "        test_idx = _extract_class_specific_idx(testset, classes)\n",
        "        test_idx = torch.where(test_idx)[0]\n",
        "        sub_test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
        "        sub_test_loader = torch.utils.data.DataLoader(\n",
        "            testset, batch_size=batch_size, sampler=sub_test_sampler)\n",
        "        testset.targets[sub_test_sampler.indices] -= offset\n",
        "\n",
        "        all_tasks.append((sub_train_loader, sub_test_loader))\n",
        "\n",
        "    dataloaders = []\n",
        "    for _ in range(num_clients):\n",
        "        i = random.choice(list(range(len(all_tasks))))\n",
        "        print(i)\n",
        "        dataloaders.append(all_tasks[i])\n",
        "\n",
        "    return dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQgAeOrKfF6R"
      },
      "source": [
        "# Custom Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOQxQIgJdpos"
      },
      "outputs": [],
      "source": [
        "#@title Custom Layer\n",
        "def KL_DIV(mu_p, sig_p, mu_q, sig_q):\n",
        "    kl = 0.5 * (2 * torch.log(sig_p / sig_q) - 1 + (sig_q / sig_p).pow(2) + ((mu_p - mu_q) / sig_p).pow(2)).sum()\n",
        "    return kl\n",
        "\n",
        "class BBBLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True, priors=None):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.use_bias = bias\n",
        "\n",
        "        if priors is None:\n",
        "            priors = {\n",
        "                'prior_mu': 0,\n",
        "                'prior_sigma': 0.01,\n",
        "            }\n",
        "\n",
        "        self.prior_W_mu = torch.tensor(priors['prior_mu'])\n",
        "        self.prior_W_sigma = torch.tensor(priors['prior_sigma'])\n",
        "        self.prior_bias_mu = torch.tensor(priors['prior_mu'])\n",
        "        self.prior_bias_sigma = torch.tensor(priors['prior_sigma'])\n",
        "\n",
        "        self.W_mu = Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.W_rho = Parameter(torch.Tensor(out_features, in_features))\n",
        "        if self.use_bias:\n",
        "            self.bias_mu = Parameter(torch.Tensor(out_features))\n",
        "            self.bias_rho = Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias_mu', None)\n",
        "            self.register_parameter('bias_rho', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.W_mu.data.normal_(0, 0.1)\n",
        "        self.W_rho.data.fill_(-3)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias_mu.data.normal_(0, 0.1)\n",
        "            self.bias_rho.data.fill_(-3)\n",
        "\n",
        "    def forward(self, x, sample=True):\n",
        "        self.W_sigma = torch.log1p(torch.exp(self.W_rho))\n",
        "        if self.use_bias:\n",
        "            self.bias_sigma = torch.log1p(torch.exp(self.bias_rho))\n",
        "            bias_var = self.bias_sigma ** 2\n",
        "        else:\n",
        "            self.bias_sigma = bias_var = None\n",
        "\n",
        "        act_mu = F.linear(x, self.W_mu, self.bias_mu)\n",
        "        # What is this line?\n",
        "        act_var = 1e-16 + F.linear(x ** 2, self.W_sigma ** 2, bias_var)\n",
        "        act_std = torch.sqrt(act_var)\n",
        "\n",
        "        if self.training or sample:\n",
        "            eps = torch.empty(act_mu.size()).normal_(0, 1).to(act_mu.device)\n",
        "            return act_mu + act_std * eps\n",
        "        else:\n",
        "            return act_mu\n",
        "\n",
        "    def kl_loss(self):\n",
        "        kl = KL_DIV(self.prior_W_mu, self.prior_W_sigma, self.W_mu, self.W_sigma)\n",
        "        if self.use_bias:\n",
        "            kl += KL_DIV(self.prior_bias_mu, self.prior_bias_sigma, self.bias_mu, self.bias_sigma)\n",
        "        return kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_09osLpRh7O"
      },
      "outputs": [],
      "source": [
        "#@title Dynamic Head Model\n",
        "\n",
        "class DynamicHeadModel(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_dim=100, hidden_layers=2):\n",
        "        super().__init__()\n",
        "        self.input_layer = BBBLinear(input_size, hidden_dim)\n",
        "        self.shared_layers = nn.ModuleList([BBBLinear(hidden_dim, hidden_dim) for _ in range(hidden_layers)])\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Initially empty, will create new heads dynamically as batches come in.\n",
        "        self.head_layers = nn.ModuleList()\n",
        "        self.num_heads = 0\n",
        "\n",
        "        self.likelihoods = []\n",
        "\n",
        "        # Create a lookup dictionary so that each batch index is linked to the\n",
        "        # index of the head that gets used on that batch (unlike in the VCL paper\n",
        "        # there is not necessarily one head per batch).\n",
        "        self.client_id_to_head_id = {}\n",
        "\n",
        "    def forward(self, x, id, use_client_id=False):\n",
        "        head_id = self.client_id_to_head_id[id] if use_client_id else id\n",
        "\n",
        "        x = x.view(-1, 784)\n",
        "        x = F.relu(self.input_layer(x))\n",
        "\n",
        "        for layer in self.shared_layers:\n",
        "            x = F.relu(layer(x))\n",
        "\n",
        "        head_to_use = self.head_layers[head_id]\n",
        "\n",
        "        return head_to_use(x)\n",
        "\n",
        "    def create_new_head(self, client_id, width):\n",
        "        print('\\nCreating a new head!')\n",
        "        new_head_id = len(self.head_layers) # 0 if no head layers yet, 1 if there is 1 etc\n",
        "        self.client_id_to_head_id[client_id] = new_head_id\n",
        "        self.head_layers.append(BBBLinear(self.hidden_dim, width).to(device))\n",
        "        self.num_heads += 1\n",
        "\n",
        "    def get_kl(self, id, use_client_id=False):\n",
        "        head_id = self.client_id_to_head_id[id] if use_client_id else id\n",
        "        kl = 0.0\n",
        "        kl += self.input_layer.kl_loss()\n",
        "        for layer in self.shared_layers:\n",
        "            kl += layer.kl_loss()\n",
        "\n",
        "        kl += self.head_layers[head_id].kl_loss()\n",
        "\n",
        "        return kl\n",
        "\n",
        "    def update_prior(self):\n",
        "        for child in self.children():\n",
        "            if child.__class__ is not nn.ModuleList:\n",
        "                child.prior_W_mu = child.W_mu.data\n",
        "                child.prior_W_sigma = child.W_sigma.data\n",
        "                if child.use_bias:\n",
        "                    child.prior_bias_mu = child.bias_mu.data\n",
        "                    child.prior_bias_sigma = child.bias_sigma.data\n",
        "            if child.__class__ is nn.ModuleList:\n",
        "                for layer in child:\n",
        "                    layer.prior_W_mu = layer.W_mu.data\n",
        "                    layer.prior_W_sigma = layer.W_sigma.data\n",
        "                    if layer.use_bias:\n",
        "                        layer.prior_bias_mu = layer.bias_mu.data\n",
        "                        layer.prior_bias_sigma = layer.bias_sigma.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6aiCCIUYmk8"
      },
      "source": [
        "# Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTK2oDN0YdCX"
      },
      "outputs": [],
      "source": [
        "#@title Baseline Permuted Model\n",
        "class PermutedModel(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_dim=100, output_dim=10):\n",
        "        self.input_size = input_size\n",
        "        super().__init__()\n",
        "        self.fc1 = BBBLinear(input_size, hidden_dim)\n",
        "        self.fc2 = BBBLinear(hidden_dim, hidden_dim)\n",
        "        self.head_layer = BBBLinear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, task_id, use_client_id=False):\n",
        "        out = x.view(-1, self.input_size)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        return self.head_layer(out)\n",
        "\n",
        "    def get_kl(self, task_id):\n",
        "        kl = 0.0\n",
        "        kl += self.fc1.kl_loss()\n",
        "        kl += self.fc2.kl_loss()\n",
        "        kl += self.head_layer.kl_loss()\n",
        "        return kl\n",
        "\n",
        "    def update_prior(self):\n",
        "        self.fc1.prior_W_mu = self.fc1.W_mu.data\n",
        "        self.fc1.prior_W_sigma = self.fc1.W_sigma.data\n",
        "        if self.fc1.use_bias:\n",
        "            self.fc1.prior_bias_mu = self.fc1.bias_mu.data\n",
        "            self.fc1.prior_bias_sigma = self.fc1.bias_sigma.data\n",
        "\n",
        "        self.fc2.prior_W_mu = self.fc2.W_mu.data\n",
        "        self.fc2.prior_W_sigma = self.fc2.W_sigma.data\n",
        "        if self.fc2.use_bias:\n",
        "            self.fc2.prior_bias_mu = self.fc2.bias_mu.data\n",
        "            self.fc2.prior_bias_sigma = self.fc2.bias_sigma.data\n",
        "\n",
        "        self.head_layer.prior_W_mu = self.head_layer.W_mu.data\n",
        "        self.head_layer.prior_W_sigma = self.head_layer.W_sigma.data\n",
        "        if self.head_layer.use_bias:\n",
        "            self.head_layer.prior_bias_mu = self.head_layer.bias_mu.data\n",
        "            self.head_layer.prior_bias_sigma = self.head_layer.bias_sigma.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-C0C4H6YiDW"
      },
      "outputs": [],
      "source": [
        "#@title Baseline Split Model\n",
        "class SplitModel(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_dim=100, output_dim=2):\n",
        "        self.input_size = input_size\n",
        "        super().__init__()\n",
        "        self.fc1 = BBBLinear(input_size, hidden_dim)\n",
        "        self.fc2 = BBBLinear(hidden_dim, hidden_dim)\n",
        "        self.head_layers = nn.ModuleList([BBBLinear(hidden_dim, output_dim) for i in range(5)])\n",
        "\n",
        "    def forward(self, x, task_id, use_client_id=False):\n",
        "        out = x.view(-1, self.input_size)\n",
        "        for layer in self.children():\n",
        "            if layer.__class__ is not nn.ModuleList:\n",
        "                out = F.relu(layer(out))\n",
        "        return self.head_layers[task_id](out)\n",
        "\n",
        "    def get_kl(self, task_id):\n",
        "        kl = 0.0\n",
        "        for layer in self.children():\n",
        "            if layer.__class__ is not nn.ModuleList:\n",
        "                kl += layer.kl_loss()\n",
        "        kl += self.head_layers[task_id].kl_loss()\n",
        "        return kl\n",
        "\n",
        "    def update_prior(self):\n",
        "        for layer in self.children():\n",
        "            if layer.__class__ is not nn.ModuleList:\n",
        "                layer.prior_W_mu = layer.W_mu.data\n",
        "                layer.prior_W_sigma = layer.W_sigma.data\n",
        "                if layer.use_bias:\n",
        "                    layer.prior_bias_mu = layer.bias_mu.data\n",
        "                    layer.prior_bias_sigma = layer.bias_sigma.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8IlTCRLfT4b"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_12aDBaPiOUl"
      },
      "outputs": [],
      "source": [
        "#@title Coreset\n",
        "def attach_random_coreset_permuted(coresets, sub_train_loader, num_samples=200):\n",
        "    \"\"\"\n",
        "    coresets: list of collection of coreset dataloaders\n",
        "    sub_train_loader: loader from which a random coreset is to be drawn\n",
        "    num_samples: number of samples in each coreset\n",
        "    \"\"\"\n",
        "    shuffled_task_indices = torch.randperm(len(sub_train_loader.dataset))\n",
        "    coreset_indices = shuffled_task_indices[:num_samples]\n",
        "    coreset_sampler = SubsetRandomSampler(coreset_indices)\n",
        "    coreset_loader = DataLoader(\n",
        "        sub_train_loader.dataset, batch_size=sub_train_loader.batch_size, sampler=coreset_sampler\n",
        "    )\n",
        "    coresets.append(coreset_loader)\n",
        "\n",
        "def attach_random_coreset_split(coresets, sub_train_loader, num_samples=200):\n",
        "    \"\"\"\n",
        "    coresets: list of collection of coreset dataloaders\n",
        "    sub_train_loader: loader from which a random coreset is to be drawn\n",
        "    num_samples: number of samples in each coreset\n",
        "    \"\"\"\n",
        "    task_indices = sub_train_loader.sampler.indices\n",
        "    shuffled_task_indices = task_indices[torch.randperm(len(task_indices))]\n",
        "    coreset_indices = shuffled_task_indices[:num_samples]\n",
        "    sub_train_loader.sampler.indices = shuffled_task_indices[num_samples:]  # Delete coreset from orginal data\n",
        "    coreset_sampler = torch.utils.data.SubsetRandomSampler(coreset_indices)\n",
        "    coreset_loader = torch.utils.data.DataLoader(\n",
        "        sub_train_loader.dataset, batch_size=sub_train_loader.batch_size, sampler=coreset_sampler)\n",
        "    coresets.append(coreset_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDy55WNx61Qc"
      },
      "outputs": [],
      "source": [
        "#@title ELBO\n",
        "class ELBO(nn.Module):\n",
        "    def __init__(self, model, beta):\n",
        "        super().__init__()\n",
        "        self.num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, outputs, targets, kl):\n",
        "        assert not targets.requires_grad\n",
        "        #print(F.nll_loss(outputs, targets, reduction='mean'), self.beta * kl / self.num_params)\n",
        "        # This should only be divided by the number of paramters that were used (in the appropriate head).\n",
        "        return F.nll_loss(outputs, targets, reduction='mean') + self.beta * kl / self.num_params\n",
        "\n",
        "def calculate_accuracy(outputs, targets):\n",
        "    return np.mean(outputs.argmax(dim=-1).cpu().numpy() == targets.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thJ8BgM2EMH7"
      },
      "outputs": [],
      "source": [
        "#@title Get Probability of Head Being the Correct One\n",
        "def get_probability_of_head(model, inputs, targets, output_nodes, head_id):\n",
        "    log_output = monte_carlo(model, inputs, output_nodes, head_id)\n",
        "    loss = F.nll_loss(log_output, targets, reduction='mean')\n",
        "    probability = torch.exp(-loss).item()\n",
        "    return probability\n",
        "\n",
        "    #inputs  = torch.cat([i for i, _ in dataloader]).to(device)\n",
        "    #targets = torch.cat([t.flatten() for _, t in dataloader]).to(device)\n",
        "    #output_nodes = torch.max(targets).item() + 1\n",
        "    #log_output = monte_carlo(model, inputs, output_nodes, head_id)\n",
        "    #loss = F.nll_loss(log_output, targets, reduction='mean')\n",
        "    #probability = torch.exp(-loss)\n",
        "    #return probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWCYS5W1kcM0"
      },
      "outputs": [],
      "source": [
        "#@title Monte Carlo\n",
        "def monte_carlo(model, inputs, output_nodes, id, use_client_id=False, no_grad=False):\n",
        "    T = 10\n",
        "    outputs = torch.zeros(inputs.shape[0], output_nodes, T).to(device)\n",
        "\n",
        "    for i in range(T):\n",
        "        if no_grad:\n",
        "            with torch.no_grad():\n",
        "                out = model(inputs, id, use_client_id)\n",
        "        else:\n",
        "            out = model(inputs, id, use_client_id)\n",
        "        outputs[:, :, i] = F.log_softmax(out, dim=-1)\n",
        "\n",
        "    log_output = torch.logsumexp(outputs, dim=-1) - np.log(T)\n",
        "\n",
        "    return log_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cILWlU6VYz96"
      },
      "source": [
        "# VCL Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhNa39IfixRs"
      },
      "outputs": [],
      "source": [
        "#@title Auto VCL Train and Predict\n",
        "def dynamic_train(model, num_epochs, dataloader, client_id, beta, replay=False):\n",
        "    beta = 0 if replay else beta\n",
        "    lr_start = 1e-3\n",
        "\n",
        "    flattened_tensor = torch.cat([t for _, t in dataloader])\n",
        "    output_nodes = torch.max(flattened_tensor).item() + 1\n",
        "\n",
        "    elbo = ELBO(model, beta)\n",
        "    optimizer = Adam(model.parameters(), lr=lr_start)\n",
        "\n",
        "    head_loss = None\n",
        "\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "    #for epoch in range(num_epochs):\n",
        "        for inputs, targets in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            # Check if we have identified this client_id with a certain head already:\n",
        "            if client_id not in model.client_id_to_head_id.keys():\n",
        "                # Otherwise, we need to find which head to use.\n",
        "                # First, calculate the loss for each existing head:\n",
        "                most_promising_head_id   = None\n",
        "                most_promising_head_prob = 0.\n",
        "                for head_id, head in enumerate(model.head_layers):\n",
        "                    if head.out_features == output_nodes:\n",
        "                        prob_of_this_head = get_probability_of_head(model, inputs, targets, output_nodes, head_id)\n",
        "                        if prob_of_this_head > most_promising_head_prob:\n",
        "                            most_promising_head_id   = head_id\n",
        "                            most_promising_head_prob = prob_of_this_head\n",
        "\n",
        "                print('\\nBest head likelihood: ', most_promising_head_prob)\n",
        "                model.likelihoods.append(most_promising_head_prob)\n",
        "\n",
        "                # If the results are too poor, create a new head for it\n",
        "                # and calculate the loss on this new head.\n",
        "                if most_promising_head_prob <= params['threshold']:\n",
        "                    # We couldn't find a strong head, so make a new one.\n",
        "                    model.create_new_head(client_id, output_nodes)\n",
        "                else:\n",
        "                    model.client_id_to_head_id[client_id] = most_promising_head_id\n",
        "\n",
        "            log_output = monte_carlo(model, inputs, output_nodes, client_id, use_client_id=True)\n",
        "            kl = model.get_kl(client_id, use_client_id=True)\n",
        "            head_loss = elbo(log_output, targets, kl)\n",
        "            head_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def dynamic_predict(model, dataloader, client_id):\n",
        "    model.eval()\n",
        "    accs = []\n",
        "\n",
        "    flattened_tensor = torch.cat([t.flatten() for _, t in dataloader])\n",
        "    output_nodes = torch.max(flattened_tensor).item() + 1\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        log_output = monte_carlo(model, inputs, output_nodes, client_id, use_client_id=True, no_grad=True)\n",
        "        accs.append(calculate_accuracy(log_output, targets))\n",
        "\n",
        "    return np.mean(accs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy3T_IQFVSzT"
      },
      "outputs": [],
      "source": [
        "#@title Auto VCL\n",
        "def dynamic_vcl(num_epochs, dataloaders, model, coreset_method, coreset_size=0, beta=1.):\n",
        "    num_batches = len(dataloaders)\n",
        "    coreset_list = []\n",
        "    all_accs = np.empty(shape=(num_batches, num_batches))\n",
        "    all_accs.fill(np.nan)\n",
        "\n",
        "    for client_id, (trainloader, testloader) in enumerate(dataloaders):\n",
        "        # Train on non-coreset data\n",
        "        dynamic_train(model, num_epochs, trainloader, client_id, beta)\n",
        "        print(\"Done Training Task\", client_id + 1)\n",
        "\n",
        "        # Attach a new coreset\n",
        "        if coreset_size > 0:\n",
        "            coreset_method(coreset_list, trainloader, num_samples=coreset_size)\n",
        "\n",
        "            # Replay old tasks using coresets\n",
        "            for task in range(client_id + 1):\n",
        "                print(\"Replaying Task\", task + 1)\n",
        "                dynamic_train(model, num_epochs, coreset_list[task], task, beta, replay=True)\n",
        "        print()\n",
        "\n",
        "        # Evaluate on old tasks\n",
        "        for client_to_retest_id in range(client_id + 1):\n",
        "            _, testloader_i = dataloaders[client_to_retest_id]\n",
        "            accuracy = dynamic_predict(model, testloader_i, client_to_retest_id)\n",
        "            print(\"Task {} Accuracy: {}\".format(client_to_retest_id + 1, accuracy))\n",
        "            all_accs[client_id][client_to_retest_id] = accuracy\n",
        "        print()\n",
        "\n",
        "        model.update_prior()\n",
        "    print(all_accs)\n",
        "    return all_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahYdBEamfdc4"
      },
      "outputs": [],
      "source": [
        "#@title Baseline Train and Predict\n",
        "def baseline_train(model, num_epochs, dataloader, task_id, replay=False):\n",
        "    beta = 0 if replay else 1\n",
        "    lr_start = 1e-3\n",
        "\n",
        "    flattened_tensor = torch.cat([t.flatten() for _, t in dataloader])\n",
        "    output_nodes = torch.max(flattened_tensor).item() + 1\n",
        "\n",
        "    elbo = ELBO(model, beta)\n",
        "    optimizer = Adam(model.parameters(), lr=lr_start)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for inputs, targets in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            log_output = monte_carlo(model, inputs, output_nodes, task_id)\n",
        "\n",
        "            kl = model.get_kl(task_id)\n",
        "            loss = elbo(log_output, targets, kl)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def baseline_predict(model, dataloader, task_id):\n",
        "    flattened_tensor = torch.cat([t.flatten() for _, t in dataloader])\n",
        "    output_nodes = torch.max(flattened_tensor).item() + 1\n",
        "\n",
        "    model.train()\n",
        "    accs = []\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        log_output = monte_carlo(model, inputs, output_nodes, task_id, no_grad=True)\n",
        "        accs.append(calculate_accuracy(log_output, targets))\n",
        "\n",
        "    return np.mean(accs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9uWtW39YTc6"
      },
      "outputs": [],
      "source": [
        "#@title Baseline VCL\n",
        "def baseline_vcl(num_tasks, num_epochs, dataloaders, model, coreset_method, coreset_size=0):\n",
        "    coreset_list = []\n",
        "    all_accs = np.empty(shape=(num_tasks, num_tasks))\n",
        "    all_accs.fill(np.nan)\n",
        "    for task_id in range(num_tasks):\n",
        "        print(\"Starting Task\", task_id + 1)\n",
        "\n",
        "        # Train on non-coreset data\n",
        "        trainloader, testloader = dataloaders[task_id]\n",
        "        baseline_train(model, num_epochs, trainloader, task_id)\n",
        "        print(\"Done Training Task\", task_id + 1)\n",
        "\n",
        "        # Attach a new coreset\n",
        "        if coreset_size > 0:\n",
        "            coreset_method(coreset_list, trainloader, num_samples=coreset_size)\n",
        "\n",
        "            # Replay old tasks using coresets\n",
        "            for task in range(task_id + 1):\n",
        "                print(\"Replaying Task\", task + 1)\n",
        "                baseline_train(model, num_epochs, coreset_list[task], task_id=task, replay=True)\n",
        "        print()\n",
        "\n",
        "        # Evaluate on old tasks\n",
        "        for task in range(task_id + 1):\n",
        "            _, testloader_i = dataloaders[task]\n",
        "            accuracy = baseline_predict(model, testloader_i, task)\n",
        "            print(\"Task {} Accuracy: {}\".format(task + 1, accuracy))\n",
        "            all_accs[task_id][task] = accuracy\n",
        "        print()\n",
        "        #if update_prior:\n",
        "        model.update_prior()\n",
        "    print(all_accs)\n",
        "    return all_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4gBsipVfuC1"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sBF5xv2DIpw",
        "outputId": "9a432111-e9ff-46d3-be3a-96aa743a9de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best head likelihood:  0.0\n",
            "\n",
            "Creating a new head!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:26<00:00,  2.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 1\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 12.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9818731117824774\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best head likelihood:  0.28782737255096436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:24<00:00,  2.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 2\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 17.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9763343403826787\n",
            "Task 2 Accuracy: 0.9343780607247796\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best head likelihood:  0.03932192176580429\n",
            "\n",
            "Creating a new head!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:23<00:00,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 3\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 18.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9778449144008057\n",
            "Task 2 Accuracy: 0.930460333006856\n",
            "Task 3 Accuracy: 0.9866595517609391\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best head likelihood:  0.0395965650677681\n",
            "\n",
            "Creating a new head!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:27<00:00,  2.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 4\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 17.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 18.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9783484390735147\n",
            "Task 2 Accuracy: 0.9363369245837414\n",
            "Task 3 Accuracy: 0.9786552828175027\n",
            "Task 4 Accuracy: 0.9966903073286052\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best head likelihood:  0.07589598000049591\n",
            "\n",
            "Creating a new head!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:26<00:00,  2.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 5\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 17.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 19.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9677744209466264\n",
            "Task 2 Accuracy: 0.93486777668952\n",
            "Task 3 Accuracy: 0.9818569903948773\n",
            "Task 4 Accuracy: 0.9976359338061466\n",
            "Task 5 Accuracy: 0.9576399394856279\n",
            "\n",
            "[[0.98187311        nan        nan        nan        nan]\n",
            " [0.97633434 0.93437806        nan        nan        nan]\n",
            " [0.97784491 0.93046033 0.98665955        nan        nan]\n",
            " [0.97834844 0.93633692 0.97865528 0.99669031        nan]\n",
            " [0.96777442 0.93486778 0.98185699 0.99763593 0.95763994]]\n",
            "Starting Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:21<00:00,  2.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 1\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 22.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9859013091641491\n",
            "\n",
            "Starting Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:21<00:00,  2.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 2\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 25.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9909365558912386\n",
            "Task 2 Accuracy: 0.9490695396669931\n",
            "\n",
            "Starting Task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:20<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 3\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 22.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.986404833836858\n",
            "Task 2 Accuracy: 0.954456415279138\n",
            "Task 3 Accuracy: 0.9861259338313767\n",
            "\n",
            "Starting Task 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:22<00:00,  2.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 4\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 17.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 16.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 20.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 24.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.986404833836858\n",
            "Task 2 Accuracy: 0.9564152791380999\n",
            "Task 3 Accuracy: 0.9749199573105657\n",
            "Task 4 Accuracy: 0.9966903073286052\n",
            "\n",
            "Starting Task 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:21<00:00,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Training Task 5\n",
            "Replaying Task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 23.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 25.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 25.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 23.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaying Task 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 24.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task 1 Accuracy: 0.9843907351460222\n",
            "Task 2 Accuracy: 0.9480901077375122\n",
            "Task 3 Accuracy: 0.9845250800426895\n",
            "Task 4 Accuracy: 0.9966903073286052\n",
            "Task 5 Accuracy: 0.9631870902672718\n",
            "\n",
            "[[0.98590131        nan        nan        nan        nan]\n",
            " [0.99093656 0.94906954        nan        nan        nan]\n",
            " [0.98640483 0.95445642 0.98612593        nan        nan]\n",
            " [0.98640483 0.95641528 0.97491996 0.99669031        nan]\n",
            " [0.98439074 0.94809011 0.98452508 0.99669031 0.96318709]]\n"
          ]
        }
      ],
      "source": [
        "#@title Run Experiments\n",
        "split_class_distribution = [\n",
        "    [0, 1],\n",
        "    [2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7],\n",
        "    [8, 9]]\n",
        "\n",
        "if params['experiment_name'] == 'permuted':\n",
        "    num_tasks = permuted_params['num_tasks']\n",
        "    coreset_size = permuted_params['coreset_size']\n",
        "    permuted_dataloaders = get_permuted_dataloaders(num_tasks)\n",
        "    epochs = permuted_params['epochs']\n",
        "    hidden_dim = permuted_params['hidden_dim']\n",
        "    if params['perform_vcl']:\n",
        "        vcl_model = PermutedModel(hidden_dim=hidden_dim).to(device)\n",
        "        vcl_accs = baseline_vcl(num_tasks, epochs, permuted_dataloaders, vcl_model, attach_random_coreset_permuted, coreset_size)\n",
        "    if params['perform_auto_vcl']:\n",
        "        auto_vcl_model = DynamicHeadModel(hidden_dim=hidden_dim).to(device)\n",
        "        auto_vcl_accs = dynamic_vcl(epochs, permuted_dataloaders, auto_vcl_model, attach_random_coreset_permuted, coreset_size, params['beta'])\n",
        "elif params['experiment_name'] == 'split':\n",
        "    coreset_size = split_params['coreset_size']\n",
        "    split_dataloaders = get_split_dataloaders(split_class_distribution)\n",
        "    epochs = split_params['epochs']\n",
        "    hidden_dim = split_params['hidden_dim']\n",
        "    if params['perform_auto_vcl']:\n",
        "        auto_vcl_model = DynamicHeadModel(hidden_dim=hidden_dim).to(device)\n",
        "        auto_vcl_accs = dynamic_vcl(epochs, split_dataloaders, auto_vcl_model, attach_random_coreset_split, coreset_size, params['beta'])\n",
        "    if params['perform_vcl']:\n",
        "        vcl_model = SplitModel(hidden_dim=hidden_dim).to(device)\n",
        "        vcl_accs = baseline_vcl(5, epochs, split_dataloaders, vcl_model, attach_random_coreset_split, coreset_size)\n",
        "elif params['experiment_name'] == 'random':\n",
        "    coreset_size = random_split_params['coreset_size']\n",
        "    random_split_dataloaders = get_random_split_dataloaders(split_class_distribution, random_split_params['num_clients'])\n",
        "    epochs = random_split_params['epochs']\n",
        "    hidden_dim = random_split_params['hidden_dim']\n",
        "    if params['perform_auto_vcl']:\n",
        "        auto_vcl_model = DynamicHeadModel(hidden_dim=hidden_dim).to(device)\n",
        "        auto_vcl_accs = dynamic_vcl(epochs, random_split_dataloaders, auto_vcl_model, attach_random_coreset_split, coreset_size, params['beta'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFK4agP-r86m"
      },
      "source": [
        "[0,\n",
        "0.0719,\n",
        "0.0217,\n",
        "0.0088,\n",
        "0.0064,\n",
        "0.0157,\n",
        "0.0095,\n",
        "0.0025,\n",
        "0.0075,\n",
        "0.0033]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPQ8lD-7Kd6J"
      },
      "source": [
        "VCL permuted, 200 coreset, 256 width, 10 epochs\n",
        "\n",
        "[[0.90957031        nan        nan        nan        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.84833984 0.96435547        nan        nan        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.85703125 0.93925781 0.96386719        nan        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.80947266 0.93740234 0.94863281 0.96210938        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.81455078 0.92714844 0.93095703 0.93476563 0.96289062        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.81083984 0.88427734 0.90664062 0.88740234 0.92841797 0.95898438\n",
        "         nan        nan        nan        nan]\n",
        " [0.77724609 0.88798828 0.90742188 0.88134766 0.90771484 0.93261719\n",
        "  0.95458984        nan        nan        nan]\n",
        " [0.79570312 0.8265625  0.88544922 0.87021484 0.88046875 0.92226562\n",
        "  0.93925781 0.95087891        nan        nan]\n",
        " [0.75341797 0.83710938 0.89394531 0.84003906 0.88671875 0.8984375\n",
        "  0.91806641 0.90839844 0.93154297        nan]\n",
        " [0.73173828 0.84921875 0.84716797 0.84707031 0.87412109 0.89970703\n",
        "  0.88632813 0.90429688 0.90976563 0.95371094]]\n",
        "\n",
        "AutoVCL permuted, 200 coreset, 256 width, 10 epochs, threshold 0.1\n",
        "\n",
        "  [[0.93964844        nan        nan        nan        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.87050781 0.97099609        nan        nan        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.83818359 0.93447266 0.97226563        nan        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.853125   0.92792969 0.94248047 0.95810547        nan        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.846875   0.92607422 0.93349609 0.92880859 0.97148437        nan\n",
        "         nan        nan        nan        nan]\n",
        " [0.82705078 0.91806641 0.92568359 0.92324219 0.95507812 0.965625\n",
        "         nan        nan        nan        nan]\n",
        " [0.83408203 0.89345703 0.90566406 0.90849609 0.92958984 0.95117188\n",
        "  0.96357422        nan        nan        nan]\n",
        " [0.80917969 0.88017578 0.89794922 0.89121094 0.92207031 0.93154297\n",
        "  0.94697266 0.95410156        nan        nan]\n",
        " [0.7984375  0.88740234 0.88300781 0.90722656 0.89091797 0.92548828\n",
        "  0.92578125 0.93994141 0.95878906        nan]\n",
        " [0.79658203 0.87373047 0.85712891 0.87724609 0.89970703 0.91044922\n",
        "  0.92109375 0.93837891 0.9453125  0.95722656]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voGzG7X3BD7h"
      },
      "source": [
        "Width 50\n",
        "\n",
        "22:52:17\n",
        "23:03:51\n",
        "100%|██████████| 10/10 [11:34<00:00, 69.44s/trial, best loss: -0.6580235272988505]\n",
        "{'beta': 0.3594520045264994}\n",
        "\n",
        "\n",
        "Width 100\n",
        "\n",
        "23:07:03\n",
        "23:19:06\n",
        "100%|██████████| 10/10 [12:03<00:00, 72.34s/trial, best loss: -0.7445559446839081]\n",
        "{'beta': 0.4821937485554201}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTkCsaCWUF4A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "09c8a34a-7f3d-4ed4-c239-dc43c207e74d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if params['experiment_name'] == 'random': print(random_split_dataloaders)\n",
        "\n",
        "if params['perform_auto_vcl']:\n",
        "    horizontal_line_y = params['threshold']\n",
        "    categories = list(range(1, len(auto_vcl_accs) + 1))\n",
        "    plt.scatter(categories, auto_vcl_model.likelihoods, marker='x', linestyle='-')\n",
        "    plt.axhline(y=horizontal_line_y, color='r', linestyle='--')\n",
        "\n",
        "if params['perform_vcl']:\n",
        "    plt.xlabel('Dataset number')\n",
        "    plt.ylabel('Best likelihood')\n",
        "\n",
        "    plt.xticks(categories)\n",
        "    plt.ylim(-0.05, 1.05)\n",
        "    plt.show()\n",
        "\n",
        "    auto_vcl_averages = np.nanmean(auto_vcl_accs, axis=1, keepdims=False)\n",
        "\n",
        "    categories = list(range(1, len(vcl_accs) + 1))\n",
        "    print(vcl_accs.shape)\n",
        "    vcl_averages = np.nanmean(vcl_accs, axis=1, keepdims=False)\n",
        "    plt.plot(categories, vcl_averages, label='VCL')\n",
        "    plt.plot(categories, auto_vcl_averages, label='AutoVCL')\n",
        "\n",
        "plt.xlabel('Number of encountered datasets')\n",
        "plt.ylabel('Average test accuracy')\n",
        "plt.xticks(categories)\n",
        "plt.legend()\n",
        "plt.ylim(0, 1.05)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}